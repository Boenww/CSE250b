{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototype selection for nearest neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to speed up nearest neighbor classification is to replace the training set by a carefully chosen\n",
    "subset of \"prototypes\". Think of a good strategy for choosing prototypes from the training set, bearing in mind that the ultimate goal is good classification performance. Assume that 1-NN will be used. Then implement and test it on the MNIST dataset, available at: http://yann.lecun.com/exdb/mnist/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Means algorithm was used, and basically each cluster of samples was replaced by the cluster\n",
    "centroid, the number of which just equals to $\\dfrac{M}{10}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation & Test\n",
    "Compare the performance to that of uniform-random selection\n",
    "### Import Libraries & MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "from mnist import MNIST\n",
    "from random import sample\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from collections import Counter\n",
    "\n",
    "print \"Reading data...\"\n",
    "mndata = MNIST('./mnist_data_files')\n",
    "images_train, labels_train = mndata.load_training()\n",
    "data_train = zip(images_train, labels_train)\n",
    "images_test, labels_test = mndata.load_testing()\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform-random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_random_M1 = 0.8898;acc_random_M2 = 0.9357;acc_random_M3 = 0.9484\n"
     ]
    }
   ],
   "source": [
    "M1 = 1000\n",
    "M2 = 5000\n",
    "M3 = 10000\n",
    "\n",
    "def random_select(data_train, size, images_test, labels_test):\n",
    "    proto_random = sample(data_train, size)\n",
    "    images_random, labels_random = zip(*proto_random)\n",
    "    neigh_random = KNeighborsClassifier(n_neighbors=1)\n",
    "    neigh_random.fit(images_random, labels_random)\n",
    "    acc_random = sum(neigh_random.predict(images_test) == labels_test) * 1.0 / len(labels_test)\n",
    "    return acc_random\n",
    "\n",
    "print(\"acc_random_M1 = \" + str(random_select(data_train, M1, images_test, labels_test)) + \";acc_random_M2 = \" + str(random_select(data_train, M2, images_test, labels_test)) + \";acc_random_M3 = \" + str(random_select(data_train, M3, images_test, labels_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condensed Nearest Neighbour (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn(labeled_train, M):\n",
    "    S, G = [labeled_train[0]], []\n",
    "    Count = 0\n",
    "    count = 0\n",
    "    for d in labeled_train:\n",
    "        neigh = KNeighborsClassifier(n_neighbors=1, p=1)\n",
    "        neigh.fit(zip(*S)[0], zip(*S)[1])\n",
    "        if neigh.predict([d[0]]) == d[1]:\n",
    "            G.append(d)\n",
    "        else:\n",
    "            S.append(d)\n",
    "            count += 1\n",
    "            print \"count = \" + str(count)\n",
    "            if len(S) == M:\n",
    "                return S\n",
    "    flg = 1\n",
    "    while G != [] and flg ==1:\n",
    "        flg = 0\n",
    "        for i in G:\n",
    "            neigh = KNeighborsClassifier(n_neighbors=1, p=1)\n",
    "            neigh.fit(zip(*S)[0], zip(*S)[1])\n",
    "            if neigh.predict([i[0]]) != i[1]:\n",
    "                S.append(i)\n",
    "                print \"round = \" + str(Count) + \";count = \" + str(count)\n",
    "                if len(S) == M:\n",
    "                    return S\n",
    "                G.remove(i)\n",
    "                flg = 1\n",
    "                break\n",
    "        Count += 1\n",
    "    return S\n",
    "\n",
    "#slow for large size\n",
    "def cnn_select(data_train, size, images_test, labels_test):\n",
    "    proto_cnn = cnn(data_train, size)\n",
    "    images_cnn, labels_cnn = zip(*proto_cnn)\n",
    "    neigh_cnn = KNeighborsClassifier(n_neighbors=1, p=1)\n",
    "    neigh_cnn.fit(images_cnn, labels_cnn)\n",
    "    acc_cnn = sum(neigh_cnn.predict(images_test) == labels_test) * 1.0 / len(labels_test)\n",
    "    return acc_cnn\n",
    "\n",
    "print(\"acc_cnn_M1 = \" + str(cnn_select(data_train, M1, images_test, labels_test)) + \";acc_cnn_M2 = \" + str(cnn_select(data_train, M2, images_test, labels_test)) + \";acc_cnn_M3 = \" + str(cnn_select(data_train, M3, images_test, labels_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_cluster_M1 = 0.9576；acc_cluster_M2 = 0.9695；acc_cluster_M3 = 0.9692\n"
     ]
    }
   ],
   "source": [
    "rus_M1 = ClusterCentroids(ratio = {1: 100, 2:100, 3: 100, 4:100, 5:100, 6:100, 7:100, 8:100, 9:100, 0:100})\n",
    "rus_M2 = ClusterCentroids(ratio = {1: 500, 2:500, 3: 500, 4:500, 5:500, 6:500, 7:500, 8:500, 9:500, 0:500})\n",
    "rus_M3 = ClusterCentroids(ratio = {1: 1000, 2:1000, 3: 1000, 4:1000, 5:1000, 6:1000, 7:1000, 8:1000, 9:1000, 0:1000})\n",
    "\n",
    "def cluster_select(rus, images_train, labels_train, images_test, labels_test):\n",
    "    images_cluster, labels_cluster = rus.fit_sample(images_train, labels_train)\n",
    "    neigh_cluster = KNeighborsClassifier(n_neighbors=1)\n",
    "    neigh_cluster.fit(images_cluster, labels_cluster)\n",
    "    acc_cluster = sum(neigh_cluster.predict(images_test) == labels_test) * 1.0 / len(labels_test)\n",
    "    return acc_cluster\n",
    "\n",
    "print(\"acc_cluster_M1 = \" + str(cluster_select(rus_M1, images_train, labels_train, images_test, labels_test)) + \"；acc_cluster_M2 = \" + str(cluster_select(rus_M2, images_train, labels_train, images_test, labels_test)) +\"；acc_cluster_M3 = \" + str(cluster_select(rus_M3, images_train, labels_train, images_test, labels_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The improvement was explicitly reflected on the performance, and also implicitly in\n",
    "the aspect of storage requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "156px",
    "width": "222px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "265px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
